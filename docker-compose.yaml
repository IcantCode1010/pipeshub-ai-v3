services:
  pipeshub-ai:
    image: pipeshub-ai:latest
    container_name: pipeshub-ai
    build:
      context: ./
      dockerfile: Dockerfile
    ports:
      - "8091:8091"
      - "8080:8080"
      - "3000:3000"
      - "8000:8000"
    env_file:
      - ./services/nodejs/apps/.env
    depends_on:
      qdrant:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '3'
          memory: 6G 

  mongodb:
    image: mongo:latest
    container_name: mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongodb_data:/data/db

  redis:
    image: redis:latest
    container_name: redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  arangodb:
    image: arangodb:latest
    container_name: arango
    restart: always
    ports:
      - "8529:8529"
    environment:
      ARANGO_ROOT_PASSWORD: your_password
    volumes:
      - arango_data:/var/lib/arangodb3

  etcd:
    image: quay.io/coreos/etcd:v3.5.17
    container_name: etcd-server
    restart: always
    ports:
      - "2379:2379"
      - "2380:2380"
    command: >
      etcd
      --name etcd-node
      --data-dir /etcd-data
      --listen-client-urls http://0.0.0.0:2379
      --advertise-client-urls http://0.0.0.0:2379
      --listen-peer-urls http://0.0.0.0:2380
      --initial-advertise-peer-urls http://0.0.0.0:2380
      --initial-cluster etcd-node=http://0.0.0.0:2380
    volumes:
      - etcd_data:/etcd-data

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    restart: always
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: controller,broker
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "record-events:1:1,entity-events:1:1,sync-events:1:1"
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_NUM_NETWORK_THREADS: 2
      KAFKA_NUM_IO_THREADS: 4
    volumes:
      - kafka_data:/var/lib/kafka/data
    command: >
      bash -c "
      kafka-storage format --cluster-id wvA_rG-9SeO5H_3LJlOj6A --config /etc/kafka/kraft/server.properties --ignore-formatted &&
      kafka-server-start /etc/kafka/kraft/server.properties
      "

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage

    # Added ulimits configuration
    ulimits:
      nofile:
        soft: 50000
        hard: 50000

    restart: always # Added restart policy

    healthcheck:
      test:
        - CMD-SHELL
        - bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  arango_data:
    driver: local
  etcd_data:
    driver: local
  kafka_data:
    driver: local
  qdrant_storage:
    driver: local
